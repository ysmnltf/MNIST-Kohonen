{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "Generating 500 samples of each digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting mnist dataset from keras\n",
    "dataset_size = 5000\n",
    "\n",
    "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "print(f\"train shape: {x_train.shape}, {y_train.shape}\")\n",
    "\n",
    "# get 5000 of data by random\n",
    "# each number should have equal distribution\n",
    "\n",
    "# find each image group (0 to 9)\n",
    "x_train_gps = [[] for x in range(10)]\n",
    "for i in range(len(x_train)):\n",
    "    x_train_gps[int(y_train[i])].append(i)\n",
    "\n",
    "# get equal amount of each number\n",
    "count = dataset_size // 10\n",
    "x = []\n",
    "for i in range(10):\n",
    "    x.append(np.random.choice(x_train_gps[i], count))\n",
    "\n",
    "# turn to numpy and shuffle\n",
    "x = np.array(x)\n",
    "x = x.flatten()\n",
    "np.random.shuffle(x)\n",
    "# normalize\n",
    "kohonen_input = np.array([\n",
    "  x_train[i].flatten() for i in x\n",
    "]) / 255\n",
    "print(\"dataset shape: \", kohonen_input.shape)\n",
    "\n",
    "# divide to minibatches\n",
    "batch_size = 25\n",
    "batch_count = kohonen_input.shape[0] // batch_size\n",
    "kohonen_minibatches = np.reshape(kohonen_input, (batch_count, -1, kohonen_input.shape[1]))\n",
    "\n",
    "print(\"dataset minibatch shape: \", kohonen_minibatches.shape)\n",
    "\n",
    "# remove extra vars\n",
    "del x\n",
    "del x_train\n",
    "del y_train\n",
    "del x_train_gps\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kohonen Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kohonen:\n",
    "    def __init__(self, x, y, feature_size, radius, lr, time_constant_r=1, time_constant_lr=1):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.feature_size = feature_size\n",
    "        self.w = None\n",
    "        self.radius = radius\n",
    "        self.lr = lr\n",
    "        self.nodes_n = x * y\n",
    "        self.iterations_n = 0\n",
    "        self.time_constant_r = time_constant_r\n",
    "        self.time_constant_lr = time_constant_lr\n",
    "        \n",
    "        \n",
    "        # step one: initialize\n",
    "        self.initialize_weights()\n",
    "        print(\"initialization complete\")\n",
    "        \n",
    "        self.neighborhoods = self.find_all_neighborhoods()\n",
    "        \n",
    "    def find_all_neighborhoods(self):\n",
    "        nodes_x, nodes_y = np.unravel_index(list(range(self.nodes_n)), (self.x, self.y))\n",
    "        dists = []\n",
    "        for i in range(self.nodes_n):\n",
    "            x = nodes_x[i]\n",
    "            y = nodes_y[i]\n",
    "            d = np.sqrt((nodes_x - x)**2 + (nodes_y - y)**2)\n",
    "            d = np.expand_dims(d, axis=1)\n",
    "            gaus_func = np.exp(- np.square(d) / (2 * np.square(self.radius)))\n",
    "            h = gaus_func\n",
    "            dists.append(h)\n",
    "        return np.array(dists).reshape((self.nodes_n, self.nodes_n))\n",
    "    \n",
    "    \n",
    "    def visualize_map(self, x, return_fast=True):\n",
    "        wmap = {}\n",
    "        im = 0\n",
    "        winners_idx = []\n",
    "        neurons_assigned = np.zeros((self.nodes_n,2), dtype=\"uint32\")\n",
    "        for i in range(x.shape[0]):\n",
    "            winn = (self.compete(x[i], return_idx_only=True))\n",
    "            winners_idx.append(winn)\n",
    "            for j in range(len(winn)):\n",
    "                neurons_assigned[winn[j]] = [i+1, j+1]\n",
    "        matched_n = (np.sum(neurons_assigned, axis=1) > 0).sum()\n",
    "        print(\"number of matched neurons: \", matched_n)\n",
    "        if (return_fast):\n",
    "            return matched_n\n",
    "        # drawing a subplot for each image\n",
    "        length = len(x)\n",
    "        fig, axes = plt.subplots(nrows=20, ncols=20, figsize=(10,10))\n",
    "        for i in range(20):\n",
    "            for j in range(20):\n",
    "                axes[i,j].axis(\"off\")\n",
    "                img_idx = neurons_assigned[i * 20 + j]\n",
    "                if (img_idx[0] == 0 and img_idx[1] == 0):\n",
    "                    continue\n",
    "                img_data = np.reshape(x[img_idx[0]-1][img_idx[1]-1], (28,28))\n",
    "                axes[i, j].imshow(img_data, cmap=\"gray\", aspect=\"auto\")\n",
    "                \n",
    "        plt.axis([0, 20, 0,  20])\n",
    "        plt.subplots_adjust(wspace=.05, hspace=.05)\n",
    "        plt.show()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        \"\"\"Randomize weights - 1s step\"\"\"\n",
    "        self.w = np.random.random((self.nodes_n, self.feature_size))\n",
    "\n",
    "    def euc_distance(self, inputs):\n",
    "        \"\"\"Calculate euclidean distance between the inputs and rows of weight\"\"\"\n",
    "        input_n = len(inputs)\n",
    "        repeated_inp = np.repeat(inputs, self.nodes_n, axis=0)\n",
    "        inp_br = np.reshape(repeated_inp, (input_n, self.nodes_n, self.feature_size)) # input_n, nodes_n, feature_size\n",
    "        # res[i]: distance of input i from each w rows\n",
    "        res = np.sqrt(np.sum((self.w - inp_br) ** 2, axis=2))\n",
    "        return res\n",
    "\n",
    "    def compete(self, inputs, return_idx_only=False):\n",
    "        \"\"\"Find the closest to the inputs for each input - 2nd step\"\"\"\n",
    "        winners_idx = np.argmin(self.euc_distance(inputs), axis=1)\n",
    "        winners = np.take(self.w, winners_idx, axis=0)\n",
    "        if (return_idx_only):\n",
    "            return winners_idx\n",
    "        return winners, winners_idx\n",
    "\n",
    "    def cooperate(self, winners_idx):\n",
    "        \"\"\"Find neighbors of winners with gaussian function - 3rd step\"\"\"\n",
    "        return np.expand_dims(np.take(self.neighborhoods, winners_idx, axis=0), axis=-1)\n",
    "\n",
    "    def adapt(self, h, inputs):\n",
    "        \"\"\"Find dw to modify the weight - 4th step\"\"\"\n",
    "        # batch\n",
    "        input_len = len(inputs)\n",
    "        inp_tiled = np.tile(inputs, [1,self.nodes_n]).reshape((input_len, self.nodes_n, -1))\n",
    "        w_tiled = np.tile(self.w, [input_len, 1]).reshape((input_len, self.nodes_n, -1))\n",
    "        dw = (self.lr * h * (inp_tiled - w_tiled))\n",
    "        dw = np.sum(dw, axis=0)\n",
    "        return dw\n",
    "\n",
    "    def iteration(self, inputs):\n",
    "        # find closest neurons - 2nd step\n",
    "        winners, winners_idx = self.compete(inputs)\n",
    "        input_n = len(inputs)\n",
    "        dw = 0\n",
    "        # find neighbors - 3rd step\n",
    "        hs = self.cooperate(winners_idx)\n",
    "        # update weights - 4rd step\n",
    "        dw = self.adapt(hs, inputs)\n",
    "        self.w += dw / input_n\n",
    "        self.w = np.clip(self.w, 0, 1)\n",
    "\n",
    "    def decay_r(self):\n",
    "        \"\"\"Decay neighborhood radius based on time_constant\"\"\"\n",
    "        self.radius = self.radius * np.exp(-self.iterations_n / self.time_constant_r)\n",
    "\n",
    "    def decay_lr(self):\n",
    "        self.lr = self.lr * np.exp(-self.iterations_n / self.time_constant_lr)\n",
    "\n",
    "\n",
    "    def train(self, minibatches, epochs, display, decay_radius=False, decay_lr=False):\n",
    "        early_stop_patience = 0\n",
    "        prev_res = 0\n",
    "        for e in range(epochs):\n",
    "            self.iterations_n += 1\n",
    "            if (display):\n",
    "                print(\"epoch \", e)\n",
    "            # stop the training if there's no change for 10 epochs\n",
    "            if (early_stop_patience >= 10):\n",
    "                print(\"no changes for 10 epochs. stopped training.\")\n",
    "            gc.collect()\n",
    "            # iterate through minibatched\n",
    "            for batch in minibatches:\n",
    "                self.iteration(batch)\n",
    "            if ((decay_lr or decay_radius)):\n",
    "                print(\"epoch \", self.iterations_n, \"  radius: \", self.radius, \", lr: \", self.lr)\n",
    "            # decay radius\n",
    "            if (decay_radius):\n",
    "                self.decay_r()\n",
    "            # decay learning rate\n",
    "            if (decay_lr):\n",
    "                self.decay_lr()\n",
    "\n",
    "            \n",
    "            if (display):\n",
    "                res = self.visualize_map(minibatches)\n",
    "                if (res == prev_res):\n",
    "                    early_stop_patience += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1:\n",
    "* Size: 20X20\n",
    "* Radius: 5\n",
    "* Learning rate: 0.01\n",
    "* No LR decay, No radius decay\n",
    "* 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = Kohonen(20, 20, kohonen_input.shape[1], 5, 0.01)\n",
    "k1.train(kohonen_minibatches, 10, display=False)\n",
    "print(\"map after 10 epochs\")\n",
    "k1.visualize_map(kohonen_minibatches, return_fast=False)\n",
    "\n",
    "k1.train(kohonen_minibatches, 10, display=False)\n",
    "print(\"map after 20 epochs\")\n",
    "k1.visualize_map(kohonen_minibatches, return_fast=False)\n",
    "\n",
    "k1.train(kohonen_minibatches, 10, display=False)\n",
    "print(\"map after 30 epochs\")\n",
    "k1.visualize_map(kohonen_minibatches, return_fast=False)\n",
    "\n",
    "k1.train(kohonen_minibatches, 10, display=False)\n",
    "print(\"map after 40 epochs\")\n",
    "k1.visualize_map(kohonen_minibatches, return_fast=False)\n",
    "\n",
    "k1.train(kohonen_minibatches, 10, display=False)\n",
    "print(\"map after 50 epochs\")\n",
    "k1.visualize_map(kohonen_minibatches, return_fast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2:\n",
    "* Size: 20X20\n",
    "* Radius: 5\n",
    "* Learning rate: 0.1\n",
    "* No radius decay\n",
    "* LR decay with time constant of 80\n",
    "* 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2 = Kohonen(20, 20, kohonen_input.shape[1], 3, 0.5, time_constant_lr=80)\n",
    "k2.train(kohonen_minibatches, 10, display=False, decay_lr=True)\n",
    "print(\"map after 10 epochs\")\n",
    "k2.visualize_map(kohonen_minibatches, return_fast=False)\n",
    "k2.train(kohonen_minibatches, 10, display=False, decay_lr=True)\n",
    "print(\"map after 20 epochs\")\n",
    "k2.visualize_map(kohonen_minibatches, return_fast=False)\n",
    "k2.train(kohonen_minibatches, 10, display=False, decay_lr=True)\n",
    "print(\"map after 30 epochs\")\n",
    "k2.visualize_map(kohonen_minibatches, return_fast=False)\n",
    "k2.train(kohonen_minibatches, 10, display=False, decay_lr=True)\n",
    "print(\"map after 40 epochs\")\n",
    "k2.visualize_map(kohonen_minibatches, return_fast=False)\n",
    "k2.train(kohonen_minibatches, 10, display=False, decay_lr=True)\n",
    "print(\"map after 50 epochs\")\n",
    "k2.visualize_map(kohonen_minibatches, return_fast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3:\n",
    "* Size: 20X20\n",
    "* Radius: 5\n",
    "* Learning rate: 0.1\n",
    "* Radius decay with time constant of 120\n",
    "* LR decay with time constant of 80\n",
    "* 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k3 = Kohonen(20, 20, kohonen_input.shape[1], 3, 10, time_constant_lr=80, time_constant_r=120)\n",
    "k3.train(kohonen_minibatches, 10, display=False, decay_lr=True, decay_radius=True)\n",
    "print(\"map after 10 epochs\")\n",
    "k3.visualize_map(kohonen_minibatches, return_fast=False)\n",
    "k3.train(kohonen_minibatches, 10, display=False, decay_lr=True, decay_radius=True)\n",
    "print(\"map after 20 epochs\")\n",
    "k3.visualize_map(kohonen_minibatches, return_fast=False)\n",
    "k3.train(kohonen_minibatches, 10, display=False, decay_lr=True, decay_radius=True)\n",
    "print(\"map after 30 epochs\")\n",
    "k3.visualize_map(kohonen_minibatches, return_fast=False)\n",
    "k3.train(kohonen_minibatches, 10, display=False, decay_lr=True, decay_radius=True)\n",
    "print(\"map after 40 epochs\")\n",
    "k3.visualize_map(kohonen_minibatches, return_fast=False)\n",
    "k3.train(kohonen_minibatches, 10, display=False, decay_lr=True, decay_radius=True)\n",
    "print(\"map after 50 epochs\")\n",
    "k3.visualize_map(kohonen_minibatches, return_fast=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
